{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MRI_Project (2).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "f1RPYxBT880j"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtIaIgd49X1U"
      },
      "source": [
        "\n",
        "\n",
        "> #          **Brain tumor classification and segmentation**\n",
        "\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRogizhLbKOg"
      },
      "source": [
        "!pip install medpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDsJ7BbjBm7v"
      },
      "source": [
        "Importing all necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AifrI2j1vvFN"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from skimage.transform import resize\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import h5py\n",
        "from skimage.color import rgb2gray\n",
        "from PIL import Image\n",
        "from medpy.io import load\n",
        "import itertools\n",
        "import sys\n",
        "import time\n",
        "\n",
        "tumor_dict = {1: 'Meningioma tumor', 2: 'Glioma tumor', 3: 'Pituitary tumor', 0: 'No tumor'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1RPYxBT880j"
      },
      "source": [
        "# Downloading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyttnO6KfK9K"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmLEIhrmwQ23"
      },
      "source": [
        "!unzip '/content/drive/My Drive/672377_1183165_bundle_archive.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-pTTmcMICj8"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQw4I9VZIKey"
      },
      "source": [
        "cd data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ3xmR9FINAm"
      },
      "source": [
        "!mkdir 3381290\n",
        "!mkdir 3381293\n",
        "!mkdir 3381296\n",
        "!mkdir 3381302"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jfwi9LVxIRFE"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEA4IK8WIXk2"
      },
      "source": [
        "!wget https://ndownloader.figshare.com/files/3381290\n",
        "!wget https://ndownloader.figshare.com/files/3381293\n",
        "!wget https://ndownloader.figshare.com/files/3381296\n",
        "!wget https://ndownloader.figshare.com/files/3381302"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgP8jMsZwaw9"
      },
      "source": [
        "!unzip './3381290' -d './data/3381290'\n",
        "!unzip './3381293' -d './data/3381293'\n",
        "!unzip './3381296' -d './data/3381296'\n",
        "!unzip './3381302' -d './data/3381302'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuK8n-sV8Sh_"
      },
      "source": [
        "!rm './3381290'\n",
        "!rm './3381293'\n",
        "!rm './3381296'\n",
        "!rm './3381302'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMqHv7gO9Pm_"
      },
      "source": [
        "# Creating custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDuQ0GUgcCJ0"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "        self.data_path = path\n",
        "        self.data_len = len(self.data_path)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      \n",
        "        if self.data_path[index][-3:] == 'mat':  # Preparing tumor images from .mat files\n",
        "\n",
        "          f = h5py.File(self.data_path[index],'r')\n",
        "          img_as_img = resize(np.array(Image.fromarray(np.array((f.get('cjdata/image')))).convert('L')), [256, 256])\n",
        "          img_as_tensor = self.to_tensor(img_as_img)\n",
        "          img_as_tensor = torch.tensor(img_as_tensor, dtype=torch.float32)\n",
        "          single_image_label = torch.tensor(f.get('cjdata/label'), dtype=torch.int32).item()\n",
        "          single_image_label = torch.tensor(single_image_label)\n",
        "          return (img_as_tensor, single_image_label)\n",
        "\n",
        "\n",
        "        else:\n",
        "\n",
        "          if self.data_path[index][18:21] == 'gli': # Preparing glioma tumor images\n",
        "\n",
        "            img_as_img = resize(np.array(Image.open(self.data_path[index].convert('L'))), [256, 256])\n",
        "            img_as_tensor = self.to_tensor(img_as_img)\n",
        "            img_as_tensor = torch.tensor(img_as_tensor, dtype=torch.float32)\n",
        "            single_image_label = torch.tensor(2)\n",
        "            return (img_as_tensor, single_image_label)\n",
        "\n",
        "\n",
        "          elif self.data_path[index][18:21] == 'men': # Preparing meningioma tumor images\n",
        "\n",
        "            img_as_img = resize(np.array(Image.open(self.data_path[index]).convert('L')), [256, 256])\n",
        "            img_as_tensor = self.to_tensor(img_as_img)\n",
        "            img_as_tensor = torch.tensor(img_as_tensor, dtype=torch.float32)\n",
        "            single_image_label = torch.tensor(1)\n",
        "            return (img_as_tensor, single_image_label)\n",
        "\n",
        "\n",
        "          elif self.data_path[index][18:21] == 'pit': # Preparing pituiary tumor images\n",
        "\n",
        "            img_as_img = resize(np.array(Image.open(self.data_path[index]).convert('L')), [256, 256])\n",
        "            img_as_tensor = self.to_tensor(img_as_img)\n",
        "            img_as_tensor = torch.tensor(img_as_tensor, dtype=torch.float32)\n",
        "            single_image_label = torch.tensor(3)\n",
        "            return (img_as_tensor, single_image_label)\n",
        "\n",
        "\n",
        "          else: # Preparing images without tumor\n",
        "            img_as_img = resize(np.array(Image.open(self.data_path[index]).convert('L')), [256, 256])\n",
        "            img_as_tensor = self.to_tensor(img_as_img)\n",
        "            img_as_tensor = torch.tensor(img_as_tensor, dtype=torch.float32)\n",
        "            single_image_label = torch.tensor(0)\n",
        "            return (img_as_tensor, single_image_label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_len\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rbT258YARvT"
      },
      "source": [
        "In this fragment of programm, all datapaths from folders collects in one array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqcMqsW6KoqT"
      },
      "source": [
        "train_images_path = []\n",
        "\n",
        "train_filenames = os.listdir('./data/3381290/')\n",
        "for fname in train_filenames:\n",
        "  train_images_path.append('./data/3381290/' + fname)\n",
        "\n",
        "train_filenames = os.listdir('./data/3381293/')\n",
        "for fname in train_filenames:\n",
        "  train_images_path.append('./data/3381293/' + fname)\n",
        "\n",
        "train_filenames = os.listdir('./data/3381296/')\n",
        "for fname in train_filenames:\n",
        "  train_images_path.append('./data/3381296/' + fname)\n",
        "\n",
        "train_filenames = os.listdir('./data/3381302/')\n",
        "for fname in train_filenames:\n",
        "  train_images_path.append('./data/3381302/' + fname)\n",
        "\n",
        "train_filenames = os.listdir('./Training/glioma_tumor/')\n",
        "for fname in train_filenames:\n",
        "  train_images_path.append('./Training/glioma_tumor/' + fname)\n",
        "\n",
        "train_filenames = os.listdir('./Training/meningioma_tumor/')\n",
        "for fname in train_filenames:\n",
        "  train_images_path.append('./Training/meningioma_tumor/' + fname)\n",
        "\n",
        "train_filenames = os.listdir('./Training/no_tumor/')\n",
        "for fname in train_filenames:\n",
        "  train_images_path.append('./Training/no_tumor/' + fname)\n",
        "  \n",
        "train_filenames = os.listdir('./Training/pituitary_tumor/')\n",
        "for fname in train_filenames:\n",
        "  train_images_path.append('./Training/pituitary_tumor/' + fname)\n",
        "\n",
        "test_images_path = []\n",
        "\n",
        "test_filenames = os.listdir('./Testing/glioma_tumor/')\n",
        "for fname in test_filenames:\n",
        "  test_images_path.append('./Testing/glioma_tumor/' + fname)\n",
        "\n",
        "test_filenames = os.listdir('./Testing/meningioma_tumor/')\n",
        "for fname in test_filenames:\n",
        "  test_images_path.append('./Testing/meningioma_tumor/' + fname)\n",
        "\n",
        "test_filenames = os.listdir('./Testing/no_tumor/')\n",
        "for fname in test_filenames:\n",
        "  test_images_path.append('./Testing/no_tumor/' + fname)\n",
        "\n",
        "test_filenames = os.listdir('./Testing/pituitary_tumor/')\n",
        "for fname in test_filenames:\n",
        "  test_images_path.append('./Testing/pituitary_tumor/' + fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnD9MhM6JJJs"
      },
      "source": [
        "Training_dataset = CustomDataset(path=train_images_path)\n",
        "Testing_dataset = CustomDataset(path=test_images_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVhqDlsDITV-"
      },
      "source": [
        "batch_size = 64\n",
        "train_batch_gen = torch.utils.data.DataLoader(Training_dataset, \n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True)\n",
        "\n",
        "test_batch_gen = torch.utils.data.DataLoader(Testing_dataset, \n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tl9BEVEAwsm"
      },
      "source": [
        "Let's look at data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zseS8HjqgGwJ"
      },
      "source": [
        "for x_b, y_b in train_batch_gen:\n",
        "  i = 0\n",
        "  plt.imshow(x_b[0, 0, ...], cmap='gray')\n",
        "  print(tumor_dict[int(y_b[i])])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBMvz3VhbKRX"
      },
      "source": [
        "# Creating and learning classsification model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBmxLMjjA98_"
      },
      "source": [
        "Selfmade classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhUqpqgSIClV"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "  def forward(self, input):\n",
        "    return input.view(input.size(0), -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUsFXxeBoMP8"
      },
      "source": [
        "class Block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride=1, activation=nn.ReLU()):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(in_channels=in_channels,  out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
        "    self.bn = nn.BatchNorm2d(out_channels)\n",
        "    self.activation = activation\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    x = self.conv(inputs)\n",
        "    x = self.bn(x)\n",
        "    x = self.activation(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joafJLwWKCkZ"
      },
      "source": [
        "model = nn.Sequential()\n",
        "\n",
        "model.add_module('block', Block(in_channels=1, out_channels=8, kernel_size=3))\n",
        "model.add_module(\"maxpool1\", nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "model.add_module('block2', Block(in_channels=8, out_channels=16, kernel_size=2))\n",
        "model.add_module(\"maxpool3\", nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "model.add_module(\"flatten\", Flatten())\n",
        "model.add_module('seventh3', nn.Linear(258064, 256))\n",
        "model.add_module('batch', nn.BatchNorm1d(256))\n",
        "model.add_module('activ', nn.ReLU())\n",
        "model.add_module('seventh4', nn.Linear(256, 50))\n",
        "model.add_module('batch1', nn.BatchNorm1d(50))\n",
        "model.add_module('activ1', nn.ReLU())\n",
        "model.add_module('eighth', nn.Linear(50, 4))\n",
        "model.add_module('softmax', nn.LogSoftmax())\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "compute_loss =  nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B0CMsZrBENL"
      },
      "source": [
        "Pretrained on CIFAR PyTorch model(ResNet18)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJszg3XVsSJY"
      },
      "source": [
        "import torchvision.models as models\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "\n",
        "model.fc = nn.Linear(in_features=512, out_features=4, bias=True)\n",
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "model.eval()\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "compute_loss =  nn.CrossEntropyLoss()\n",
        "\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/MRI_Models/model'))\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjiYfO3lBR-e"
      },
      "source": [
        "\n",
        "Let's train classification model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZdFqCFJLDSf",
        "scrolled": true
      },
      "source": [
        "%%time\n",
        "history = []\n",
        "N_EPOCHS=5\n",
        "test_batch_acc = []\n",
        "\n",
        "import time\n",
        "model.train(True)\n",
        "for i in range(N_EPOCHS):\n",
        "    model.train(True)\n",
        "    for (x_batch, y_batch) in train_batch_gen:\n",
        "        \n",
        "        model.train(True)\n",
        "        y_pred = model(x_batch)\n",
        "        loss = compute_loss(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "        \n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        history.append(loss)\n",
        "        \n",
        "        model.train(False)\n",
        "        for (x_batch, y_batch) in test_batch_gen:\n",
        "          logits = model(x_batch)\n",
        "          y_pred = logits.max(1)[1].data.numpy()\n",
        "          test_batch_acc.append(np.mean(y_batch.data.numpy() == y_pred))\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/MRI_Models/model')\n",
        "    print('Accuracy on test {}%'.format(round(np.mean(test_batch_acc)*100, 2)))\n",
        "    torch.save(model.state_dict(), '/content/drive/MyDrive/MRI_Models/model')\n",
        "\n",
        "plt.plot(history)\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/MRI_Models/model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSiBAt7CUYWI"
      },
      "source": [
        "model.train(False)\n",
        "test_batch_acc = []\n",
        "for (x_batch, y_batch) in test_batch_gen:\n",
        "  logits = model(x_batch)\n",
        "  y_pred = logits.max(1)[1].data.numpy()\n",
        "  test_batch_acc.append(np.mean(y_batch.data.numpy() == y_pred))\n",
        "print('Accuracy on test {}%'.format(round(np.mean(test_batch_acc)*100, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMSsS6W6bKRv"
      },
      "source": [
        "# Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3S0NqtZbKRv"
      },
      "source": [
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "        self.data_path = path\n",
        "        self.data_len = len(self.data_path)\n",
        "        \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        f = h5py.File(self.data_path[index],'r')\n",
        "        img_as_img = resize(np.array(Image.fromarray(np.array((f.get('cjdata/image')))).convert('L')), [256, 256])\n",
        "        img_as_tensor = self.to_tensor(img_as_img)\n",
        "        img_as_tensor = torch.tensor(img_as_tensor, dtype=torch.float32)\n",
        "        mask_as_img = img_as_img = resize(np.array(Image.fromarray(np.array((f.get('cjdata/tumorMask')))).convert('L')), [256, 256])\n",
        "        mask_as_tensor = self.to_tensor(mask_as_img)\n",
        "        mask_as_tensor = torch.tensor(mask_as_tensor, dtype=torch.float32)\n",
        "        return (img_as_tensor, mask_as_tensor)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_len\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlNjIJnBbKRz"
      },
      "source": [
        "Segmentation_training_dataset = SegmentationDataset(path = train_images_path[:2500])\n",
        "Segmentation_testing_dataset = SegmentationDataset(path = train_images_path[2500:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZexjHHKbKR5"
      },
      "source": [
        "batch_size = 64\n",
        "train_batch_gen_ = torch.utils.data.DataLoader(Segmentation_training_dataset, \n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True)\n",
        "\n",
        "test_batch_gen_ = torch.utils.data.DataLoader(Testing_dataset, \n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIzqAh32bKSC"
      },
      "source": [
        "def calc_iou(prediction, ground_truth):\n",
        "    n_images = len(prediction)\n",
        "    intersection, union = 0, 0\n",
        "    for i in range(n_images):\n",
        "        intersection += np.logical_and(prediction[i] > 0, ground_truth[i] > 0).astype(np.float32).sum() \n",
        "        union += np.logical_or(prediction[i] > 0, ground_truth[i] > 0).astype(np.float32).sum()\n",
        "    return float(intersection) / union"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nxjtOYEbKSE"
      },
      "source": [
        "class MyUnet(nn.Module):\n",
        "    def __init__(self, filters):\n",
        "        super(MyUnet, self).__init__()\n",
        "        self.filters = filters\n",
        "\n",
        "        encoder_layers = []\n",
        "        in_filters = 1\n",
        "        for i, ifilters in enumerate(filters):            \n",
        "            encoder_layers.append(nn.ModuleList([\n",
        "                nn.MaxPool2d(2),\n",
        "\n",
        "                nn.Conv2d(in_filters, ifilters, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(ifilters),\n",
        "                nn.ReLU(),\n",
        "\n",
        "                nn.Conv2d(ifilters, ifilters, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(ifilters),\n",
        "                nn.ReLU(),\n",
        "            ]))\n",
        "            in_filters = ifilters\n",
        "        self.encoder_list = encoder_layers\n",
        "        [self.add_module('encoder_' + str(i), layer) for i, layer in enumerate(list(itertools.chain(*self.encoder_list)))]\n",
        "\n",
        "        decoder_layers = []\n",
        "        for i in range(len(filters) - 1):\n",
        "            print(i)\n",
        "            print('filters ', -i -2,  '', filters[-i-2])\n",
        "            decoder_layers.append(([\n",
        "                nn.ConvTranspose2d(filters[-i - 1], filters[-i - 2], kernel_size=2, stride=2),\n",
        "                nn.Conv2d(filters[-i - 1], filters[-i - 2], kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(filters[-i - 2]),\n",
        "                nn.ReLU(),\n",
        "\n",
        "                nn.Conv2d(filters[-i - 2], filters[-i - 2], kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(filters[-i - 2]),\n",
        "                nn.ReLU()\n",
        "                ]))\n",
        "        decoder_layers.append(\n",
        "            ([nn.ConvTranspose2d(filters[0], filters[0], kernel_size=2, stride=2)]))\n",
        "        \n",
        "        self.decoder_list = decoder_layers\n",
        "        self.encoder_outputs = []\n",
        "        [self.add_module('decoder_' + str(i), layer) for i, layer in enumerate(list(itertools.chain(*self.decoder_list)))]\n",
        "        \n",
        "        self.head_list = [nn.Conv2d(filters[0], 1, kernel_size=1), nn.Sigmoid()]\n",
        "        [self.add_module('my_head' + str(i), layer) for i, layer in enumerate(self.head_list)]\n",
        "\n",
        "    def encoder(self, x):\n",
        "        output = x\n",
        "        for i, block in enumerate(self.encoder_list):\n",
        "            for j, layer in enumerate(block):\n",
        "                output = layer(output)\n",
        "            self.encoder_outputs.append(output)\n",
        "        return output\n",
        "\n",
        "    def decoder(self, x):\n",
        "        output = x\n",
        "        for i, block in enumerate(self.decoder_list[:-1]):\n",
        "            upsampled_x = block[0](output)\n",
        "            encoder_tensor = self.encoder_outputs[-i - 2]\n",
        "            output = torch.cat([encoder_tensor, upsampled_x], 1)\n",
        "            for j, layer in enumerate(block[1:]):\n",
        "                output = layer(output)\n",
        "        output = self.decoder_list[-1][0](output)\n",
        "        return output\n",
        "            \n",
        "    def forward(self, x):\n",
        "        encoder_output = self.encoder(x)\n",
        "        decoder_output = self.decoder(encoder_output)\n",
        "        output = self.head_list[0](decoder_output)\n",
        "        self.encoder_outputs = []\n",
        "        return self.head_list[1](output)\n",
        "\n",
        "my_filters = [10, 20, 40]\n",
        "\n",
        "seg_model = MyUnet(my_filters)\n",
        "opt = torch.optim.Adam(seg_model.parameters(), lr=1e-3)\n",
        "compute_loss =  nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWu_GYEqVc9q"
      },
      "source": [
        "seg_model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
        "    in_channels=3, out_channels=1, init_features=32, pretrained=True)\n",
        "\n",
        "seg_model.encoder1.enc1conv1 = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "seg_model.eval()\n",
        "\n",
        "opt = torch.optim.Adam(seg_model.parameters(), lr=1e-3)\n",
        "compute_loss =  nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h2sruTobKSN"
      },
      "source": [
        "%%time\n",
        "history = []\n",
        "N_EPOCHS=2\n",
        "test_accuracy = []\n",
        "use_cuda = torch.cuda.is_available()\n",
        "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
        "\n",
        "for i in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    seg_model.train(True)\n",
        "    for (x_batch, y_batch) in train_batch_gen_:\n",
        "        y_pred = seg_model(x_batch)\n",
        "        loss = compute_loss(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        opt.zero_grad()\n",
        "        history.append(loss)\n",
        "\n",
        "        seg_model.train(False)\n",
        "        for X_batch, y_batch in test_batch_gen_:\n",
        "\n",
        "          logits = seg_model(torch.FloatTensor(X_batch)).cpu().data.numpy()\n",
        "          y_pred = (logits > 0.3).astype(np.float32)\n",
        "\n",
        "          test_accuracy.append(calc_iou(y_pred.cpu(), y_batch.cpu().data.numpy()))\n",
        "\n",
        "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
        "            i + 1, N_EPOCHS, time.time() - start_time))\n",
        "    print(\"  test accuracy: \\t\\t\\t{:.2f} %\".format(\n",
        "            np.mean(test_accuracy[-1]) * 100))\n",
        "    \n",
        "\n",
        "plt.plot(history)\n",
        "torch.save(seg_model.state_dict(), '/content/drive/MyDrive/MRI_Models')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZs9hBHeo_eN"
      },
      "source": [
        "# Creating final algoritm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWOpzLX6p7Lx"
      },
      "source": [
        "import torchvision.models as model\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(in_features=512, out_features=4, bias=True)\n",
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "model.eval()\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/MRI_Models/model'))\n",
        "model.eval()\n",
        "\n",
        "seg_model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
        "    in_channels=3, out_channels=1, init_features=32, pretrained=True)\n",
        "seg_model.encoder1.enc1conv1 = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "seg_model.eval()\n",
        "seg_model.load_state_dict(torch.load('/content/drive/MyDrive/MRI_Models/seg_model'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP706NGQV_zL"
      },
      "source": [
        "image_path = input('Введите путь до необходимого изображения: \\n')\n",
        "img_as_img = resize(np.array(Image.open(image_path).convert('L')), [256, 256])\n",
        "img_as_tensor = torch.tensor(img_as_img, dtype=torch.float32)\n",
        "\n",
        "logits = model(img_as_tensor) \n",
        "y_pred = logits.max(1)[1].data.numpy()\n",
        "\n",
        "logits = seg_model(torch.FloatTensor(img_as_tensor)).data.numpy()\n",
        "y_pred = (logits > 0.3).astype(np.float32)\n",
        "\n",
        "print(tumor_dict[y_pred])\n",
        "plt.imshow(img_as_tensor, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}